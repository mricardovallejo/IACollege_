{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0847b58a",
   "metadata": {},
   "source": [
    "# Cours 5:  PMC avec Keras\n",
    "\n",
    "Author: Ricardo Vallejo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d34f313a",
   "metadata": {},
   "source": [
    "L’objectif de ces exercices est de pratiquer le perceptron simple et le perceptron multicouche en utilisant la \n",
    "bibliothèque Keras.\n",
    "Soit l’ensemble des données Segmentation (disponible aussi sur Lea) qui\n",
    "comprend 2310 observations d’images décrites par 19 variables (caractéristiques) et leurs variable cibles (classe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5561a0f",
   "metadata": {},
   "source": [
    "### 1. Téléchargez le contenu de la base de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d85a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. Téléchargez le contenu de la base de données iris\n",
    "\n",
    "data = pd.read_excel(\"segmentation.xlsx\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = data.loc[:, data.columns != 'classe']\n",
    "dataY = data[['classe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c24788a",
   "metadata": {},
   "source": [
    "### 2. Procédez à une standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce30fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "datax_std = scaler.fit_transform(dataX)\n",
    "dfx_std =  pd.DataFrame(datax_std, columns = [dataX.columns])\n",
    "dfx_std.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54811b5",
   "metadata": {},
   "source": [
    "### 3. Déterminez les différentes classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('classe').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbdc15",
   "metadata": {},
   "source": [
    "### 4. Considérez une partition de 70% pour l’entrainement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ef2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std_tot = pd.concat([dfx_std, dataY], axis = 1)\n",
    "df_std_tot =  df_std_tot.set_axis([data.columns], axis=1, inplace=False) #pd.DataFrame(df_std_tot, columns = data.columns)\n",
    "df_std_tot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3666d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df_std_tot, test_size = 0.3, stratify = df_std_tot['classe'], random_state = 10) #40% data for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03350e4",
   "metadata": {},
   "source": [
    "### 5. Vérifiez la taille de l’échantillon d’entrainement et de test par classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d213b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop = True, inplace = True)\n",
    "test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18422882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['classe'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae127e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test['classe'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a540e",
   "metadata": {},
   "source": [
    "### 6. Développez un perceptron simple et une architecture séquentielle (activation=’softmax’, optimizer=’adam’)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c8c97",
   "metadata": {},
   "source": [
    "### 6.1.  Data Model Train Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#encodage de classes\n",
    "encoder =OneHotEncoder()\n",
    "encodedTrainTarget = encoder.fit_transform(train[[\"classe\"]])\n",
    "labelsTrain=pd.DataFrame(encodedTrainTarget.toarray(), columns=encoder.categories_)\n",
    "labelsTrain.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566cff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation\n",
    "df_train_tot=pd.concat([train,labelsTrain],  axis=1)\n",
    "df_train_tot.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c189074",
   "metadata": {},
   "source": [
    "### 6.2.  Data Model Test Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodage de classes\n",
    "encoder =OneHotEncoder()\n",
    "encodedTestTarget = encoder.fit_transform(test[[\"classe\"]])\n",
    "encodedTestTarget\n",
    "\n",
    "labelsTest=pd.DataFrame(encodedTestTarget.toarray(), columns=encoder.categories_)\n",
    "labelsTest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea50f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenation\n",
    "df_test_tot=pd.concat([test,labelsTest],axis=1)\n",
    "df_test_tot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tot.drop(columns=['classe'],inplace=True)\n",
    "df_test_tot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tot.drop(columns=['classe'],inplace=True)\n",
    "df_train_tot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08371bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_train_tot[['region_centroid_col', 'region_centroid_row', 'region_pixel_count',\n",
    "       'short_line_density_5', 'short_line_density_2', 'vedge_mean',\n",
    "       'vegde_sd', 'hedge_mean', 'hedge_sd', 'intensity_mean', 'rawred_mean',\n",
    "       'rawblue_mean', 'rawgreen_mean', 'exred_mean', 'exblue_mean',\n",
    "       'exgreen_mean', 'value_mean', 'saturation_mean', 'hue_mean']]\n",
    "\n",
    "y_train=df_train_tot[['brickface', 'cement', 'foliage',  'grass', 'path', 'sky', 'window']]\n",
    "\n",
    "X_test=df_test_tot[['region_centroid_col', 'region_centroid_row', 'region_pixel_count',\n",
    "       'short_line_density_5', 'short_line_density_2', 'vedge_mean',\n",
    "       'vegde_sd', 'hedge_mean', 'hedge_sd', 'intensity_mean', 'rawred_mean',\n",
    "       'rawblue_mean', 'rawgreen_mean', 'exred_mean', 'exblue_mean',\n",
    "       'exgreen_mean', 'value_mean', 'saturation_mean', 'hue_mean']]\n",
    "\n",
    "y_test=df_test_tot[['brickface', 'cement', 'foliage',  'grass', 'path', 'sky', 'window']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73126b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b3361",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f102996",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201512b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture séquentielle (activation=’softmax’, optimizer=’adam’)\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "# Couches\n",
    "from keras.layers import Dense\n",
    "\n",
    "PMC = Sequential()\n",
    "\n",
    "# Perceptron simple: Ajout de la couche \"entrée -> sortie\"\n",
    "# Dense pour avoir des neurones complètement ement connectés\n",
    "# mYTrain.shape[1] : nb de modalités de la var. cible en sortie\n",
    "# X_train.shape[1] : dimension du vecteur de caractéristiques en entrée\n",
    "# Fonction d'activation \"Softmax\"\n",
    "\n",
    "PMC.add(Dense(units=labelsTrain.shape[1],input_dim=X_train.shape[1],activation='softmax'))\n",
    "PMC.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print('Number of layers :',len(PMC.layers)) \n",
    "\n",
    "\n",
    "# fit model\n",
    "results = PMC.fit(X_train, y_train,validation_data=(X_test, y_test),epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de l'architecture mise en place\n",
    "PMC.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur l'ensemble des données de test\n",
    "# Permet de calculer les probabilités d'appartenance à chacune des classes:\n",
    "# Score d'appartenance aux classes\n",
    "YtestpredPS = PMC.predict(X_test)  # X es normalized data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23348cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "YtestpredPS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96565b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déterminer le score d'Appartenance max par ligne\n",
    "# pour convertir les score en un indice de classes d'appartenance\n",
    "idPredPS = np.argmax(YtestpredPS,axis=1)\n",
    "print(idPredPS[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd737b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation des numéros en classes prédites\n",
    "clPredPS = labelsTrain.columns[idPredPS]\n",
    "print(clPredPS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d678a0",
   "metadata": {},
   "source": [
    "## 7. Représentez la matrice de confusion et évaluez les performances en utilisant classification_report..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5190ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "cm = confusion_matrix(ytest, YtestpredPS)\n",
    "\n",
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# confusion matrix sns heatmap \n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "3d9eb1de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-524-6a2d92ad344b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Matrice de confusion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclPredPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    277\u001b[0m         if (not hasattr(y[0], '__array__') and isinstance(y[0], Sequence)\n\u001b[0;32m    278\u001b[0m                 and not isinstance(y[0], str)):\n\u001b[1;32m--> 279\u001b[1;33m             raise ValueError('You appear to be using a legacy multi-label data'\n\u001b[0m\u001b[0;32m    280\u001b[0m                              \u001b[1;34m' representation. Sequence of sequences are no'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m                              \u001b[1;34m' longer supported; use a binary array or sparse'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "333# Matrice de confusion\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test,clPredPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fe897",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest, YtestpredPS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196344f4",
   "metadata": {},
   "source": [
    "### 9. Développez un perceptron multicouche (2 couches cachées à 30 neurones, fonctions d’activation ReLu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a02aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La fonction de perte utilisée est la perte d’entropie croisée\n",
    "#La fonction loss peut prendre les paramètres suivants :\n",
    "#\u0005 Cas de classification binaire (Binary Cross-Entropy) :\n",
    "#BinaryCrossentropy\n",
    "#\u0005 Cas de classification multi-classe (Categorical Cross-Entropy)\n",
    "#CategoricalCrossentropy\n",
    "\n",
    "\n",
    "def create_model(optimizer='adam',activation='relu'):\n",
    "\n",
    "    model = Sequential()\n",
    "    # Ajout de la premiere couche \"entree −> cachee\"\n",
    "    # 30 neurones dans la premiere couche cachee\n",
    "    # ZTrain . shape[1] : dimension du vecteur de caracteristiques en entree\n",
    "    model.add(layers.Dense( units=30,input_dim=X_train.shape[1] , activation=activation ) )\n",
    "    # Ajout de la seconde couche \"cachee −> cachee\"\n",
    "    # 30 neurones dans la deuxieme couche cachee\n",
    "    model.add(layers.Dense(30, activation=activation ) )\n",
    "    # Ajout de la troisieme couche \"cachee −> so r tie \"\n",
    "    # mYTrain. shape[1] neurones dans la couche cachee =\n",
    "    # nb de modalites de la variable cible\n",
    "\n",
    "    model.add(layers.Dense( units=y_train.shape[1] , activation='softmax') )\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "d87dc660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=30, batch_size=10, verbose=0)\n",
    "\n",
    "\n",
    "# define the grid search parameters\n",
    "#on va tester les fonctions d'activation et les optimizateurs\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "activation = ['softmax', 'relu','sigmoid','softplus','softsign','tanh','selu','elu']\n",
    "\n",
    "param_grid = dict(optimizer=optimizer,activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "grid_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d142fa7",
   "metadata": {},
   "source": [
    "### 10. . Représentez la matrice de confusion et évaluez les performances en utilisant classification_report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(ytest, ypred)\n",
    "print(matrix)\n",
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e885592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e4398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02230368",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
